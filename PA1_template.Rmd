---
title: 'Reproducible Research: Peer Assessment 1'
author: "E.A.D."
output:
  html_document:
    keep_md: yes
---

## Introduction
Welcome to the RMarkdown document for the first Peer Assessment of the course "Reproducible Research" from Coursera. This document will describe the steps taken for the data analysis and include code chunks to generate the output necessary for answering the questions.

Since this is not supposed a CodeBook or a README, the data and variables will not be further described. If you want to have a description of the data, please access [this page](https://class.coursera.org/repdata-011/human_grading/view/courses/973512/assessments/3/submissions).

## Loading necessary packages

This analysis will require some external packages: **ggplot2**, and **plyr**. Load them with the **library** command.

```{r, results='hide'}
library(plyr)
library(ggplot2)
```


## Loading and preprocessing the data

Set the working directory to the folder where the data file **activity.zip** is located using the **set.wd("...")** command in R. The next code chunk unzips the data into the csv file and reads the data into the R environment, it is saved as the variable *data*:

```{r}
unzip("activity.zip")
data <- read.csv("activity.csv")
```

Let's have a first look at it:

```{r}
dim(data)
head(data)
tail(data)
```

So we know we have three variables: the number of steps taken, the day of the measurement and the interval identifier. The interval identifier is actually the hour and minute of the measurement, i.e. 2355 corresponds to 23:55. It is not really necessary to convert this column to a time format, so let's leave it as it is. We can already see that there are a couple of NA's there too. There are a total of 17568 observations.

Let's check what is the class of the date column:
 
```{r}
class(data$date)
```

It seems that the date column is saved as a factor. Let's transform that to a Date type:

```{r}
data$date <- as.Date(data$date, format = "%Y-%m-%d")
head(data$date)
class(data$date)
```

That looks better now. We can move on to the next question.

## What is mean total number of steps taken per day?

In order to answer this question, we need the sum of total steps taken during each day. Here we can apply plyr's **ddply** function to apply the function **sum** to each day. Since we can ignore the missing values, let's just remove them from the set using **na.rm**:

```{r}
daily_steps_sum <- ddply(data, .(date), function(x) sum(x$steps, na.rm = TRUE))
names(daily_steps_sum) <- c("date", "total_steps")
head(daily_steps_sum)
```

The data frame *daily_steps_sum* has the sum of steps for each day. We can now use a histogram to check the frequency of steps taken during different days.

```{r, fig.height=4}
qplot(total_steps, data = daily_steps_sum, geom = "histogram", xlab = "Steps per day", ylab = "Count", binwidth = 1000)
```

It seems that there are many days where very few steps or none at all were measured. For the next step we can calculate the mean and the median of steps taken during each day (for each day). We can use **ddply** again, just changing the function that will be applied for each day:

```{r}
daily_steps_mean <- ddply(data, .(date), function(x) mean(x$steps, na.rm = TRUE))
names(daily_steps_mean) <- c("date", "mean_steps")
head(daily_steps_mean)

daily_steps_median <- ddply(data, .(date), function(x) median(x$steps, na.rm = TRUE))
names(daily_steps_median) <- c("date", "median_steps")
head(daily_steps_median)
```

The median is not very useful in this case, since there are so many measurements where no steps were taken. The median is therefore always 0 for these days.

We can nevertheless just take the mean and median of all days:

```{r}
mean(daily_steps_sum$total_steps)
median(daily_steps_sum$total_steps)
```

## What is the average daily activity pattern?

In order to study the average daily activity pattern let's firstly apply the average function to each daily 5-minute interval. We can do that using **ddply** again:

```{r}
activity <- ddply(data, .(interval), function(x) mean(x$steps, na.rm = TRUE))
names(activity) <- c("interval", "average_steps")
```

Now that we have this data, we can create a line plot of the intervals and the average of number steps taken:

```{r, fig.height=4}
qplot(interval, average_steps, data = activity, geom = "line", xlab = "Time of the day", ylab = "Average number of steps taken") + scale_x_continuous(breaks = seq(0, 2355, 250))
```

From the graph we can alrady see that most steps were taken between the intervals 750 and 1000, therefore between 7:50 and 10:00. We can calculate the 5-minute interval with the maximum number of steps with the **which.max** function to index the activity data table:

```{r}
activity[which.max(activity$average_steps), ]
```

So, in the interval **835**, which corresponds to 8:35, the maximum *average_steps of around* **206** steps was measured over all days.

## Imputing missing values

As we noticed earlier, there are some missing values (NA's) in this data set. Let's calculate exactly how many rows have missing values:

```{r}
length(which(is.na(data$steps)))
```

There are **2304** rows with missing values. Let's do something about that. I would say it makes sense to substitute the NA's with the average of the steps taken from the same 5-minute interval. We have this information already stored in the **activity** data set.

Firstly, we can create another column in the data set which has the average number of steps per day. We can use the **merge** function to merge the *activity* data set to the main data. This will be a new data set:

```{r}
complete_data <- merge(activity, data, by = "interval")
head(complete_data)
```

It looks good, but it seems that the order of the rows has been changed, let's arrange this:

```{r}
complete_data <- arrange(complete_data, date)
head(complete_data)
```

Much better. Now we can substitute the NA's by the average values. There are many ways to do that, but we can simply assign the average steps to the missing values by indexing them:

```{r}
indices <- is.na(complete_data$steps)
complete_data$steps[indices] <- complete_data$average_steps[indices]
head(complete_data)
length(which(is.na(complete_data$steps)))
```

So, all NA's were substituted for the average number of steps taken in the same interval over all measured days. Let's see how this affects the calculations that we've made already.

Firstly, we can examine the total number of steps taken each day using an histogram. We can repeat the same calculations made for the second step:

```{r, fig.height=4}
daily_steps_sum2 <- ddply(complete_data, .(date), function(x) sum(x$steps))
names(daily_steps_sum2) <- c("date", "total_steps")
qplot(total_steps, data = daily_steps_sum2, geom = "histogram", xlab = "Steps per day", ylab = "Count", binwidth = 1000)
```

The difference is quite clear. We can observe that the count for 0 steps has greatly reduced and the frequency for steps around 10,000 has increased. Let's check how our imputing has changed the mean and median values for **all** days:

```{r}
mean(daily_steps_sum2$total_steps)
median(daily_steps_sum2$total_steps)
```

Both the mean and the median value are higher. This was already expected, since by adding the average number of steps for an interval which had before a NA, we are increasing the total number of steps and therefore also increasing the mean. It is interesting to see that the mean is equal to the median in this case.

## Are there differences in activity patterns between weekdays and weekends?

In order to answer this question we first need to find out which days are weekdays and which are weekends. We can do that by mutating the complete data set and creating a new column **day_type** with factors defining if the day was either in a weekend or if it was a weekday. For this task I will use a conditional mutate:

```{r}
complete_data <- mutate(complete_data, daytype = factor(ifelse(weekdays(complete_data$date) %in% c("Sunday", "Saturday"), "Weekend", "Weekday")))
head(complete_data)
table(complete_data$daytype)
```

Now that we have added the daytype to the complete datas set, we can simply create a new summarized data set for the averaged number of steps per interval. We can use the **ddply** function here again, just adding the daytype variable to split the new data frame:

```{r}
activity_daytype <- ddply(complete_data, .(interval, daytype), function(x) mean(x$steps))
names(activity_daytype)[3] <- "average_steps"
head(activity_daytype)
```

The activity_daytype data frame has therefore the average steps for all intervals from 0 to 2355 and differentiates between weekdays and weekends. Now it is very easy to create our panel plot for the average number of steps taken during weekdays and weekends. **ggplot2** and its facet wrapping is great for this:

```{r}
ggplot(activity_daytype, aes(interval, average_steps, color = factor(daytype))) + geom_line() + facet_wrap(~daytype, nrow=2, scales="free") + labs(x = "Time of the day", y = "Average number of steps taken") + scale_x_continuous(breaks = seq(0, 2355, 250)) + scale_color_brewer(palette = "Set1") + theme(legend.position = "none")
```

Now that we have this graph, we can observe that there the pattern is slightly different for the weekend. The number of maximum average steps during the weekends is slightly lower (around 160), while during weekdays it is 206, as seen above. Nevertheless, it seems that during the weekends the person observed walked more than during weekdays, so we can assume that he/she is an office worker. The waking/sleeping cycle seems to be very similar, since the activity starts generally after 5 AM and reaches its peak after 8 AM.

Concluding, we have analysed a data set with many missing values, which caused the values to be slightly lower in the first analysis. After imputing the NA's we found values to be reasonable and separated the observations in weekdays and weekends. There we found a slightly lower number of steps taken during the morning, but the rest of the pattern was very similar.
